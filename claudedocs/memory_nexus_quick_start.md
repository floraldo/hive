# Intelligent Task & Memory Nexus - Quick Start Guide

**Status**: Production-Ready
**Estimated Setup Time**: 5 minutes

---

## üöÄ Quick Start (3 Steps)

### **Step 1: Initialize the Database** (30 seconds)

The schema migration runs automatically on first use:

```python
from hive_orchestration.database import init_db

# Initialize orchestration DB with memory columns
init_db()
```

**What happens**: Adds 4 memory columns to tasks table (summary, generated_artifacts, related_document_ids, knowledge_fragments)

---

### **Step 2: Start the Librarian** (Real-time Indexing)

```python
from hive_archivist.services.librarian import LibrarianService
from hive_bus import get_event_bus

# Get event bus instance
bus = get_event_bus()

# Create and start librarian
librarian = LibrarianService(bus=bus)
await librarian.start()

# Librarian now auto-indexes all completed tasks!
```

**What happens**:
- Listens for `task.completed` events
- Parses tasks into knowledge fragments
- Generates embeddings and stores in ChromaDB
- Updates task DB with vector IDs

---

### **Step 3: Enable Context for Agents**

```python
from hive_ai.agents.agent import SimpleTaskAgent, AgentConfig
from hive_ai.memory.context_service import ContextRetrievalService
from hive_ai.vector.store import VectorStore
from hive_ai.vector.embedding import EmbeddingManager
from hive_config import VectorConfig, create_config_from_sources

# Setup context service
config = create_config_from_sources().ai
vector_config = VectorConfig(
    provider="chromadb",
    collection_name="hive_knowledge",
    dimension=384
)

vector_store = VectorStore(vector_config)
embedding_manager = EmbeddingManager(config)
context_service = ContextRetrievalService(vector_store, embedding_manager)

# Create agent with context enabled
agent = SimpleTaskAgent(
    task_prompt="Your task here",
    config=AgentConfig(name="smart-agent", model="claude-3-sonnet"),
    model_client=model_client
)

# Inject context service
agent.context_service = context_service

# Run with automatic context injection
result = await agent.run_async(input_data={
    'task_id': 'task-123',
    'description': 'Deploy v2.1 to production'
})
```

**What happens**:
- Agent receives task-relevant context before execution (80-90% token reduction)
- Agent can search knowledge base mid-task via `search_long_term_memory()` tool
- Context window automatically cleaned at 80% threshold

---

## üìã CLI Usage

### **List Tasks**

```bash
# JSON output (default - for scripts)
hive tasks list

# Filter by status
hive tasks list --status completed --limit 5

# Human-readable table
hive tasks list --pretty

# Filter by worker
hive tasks list --user worker-1 --pretty
```

### **Show Task Detail**

```bash
# JSON output
hive tasks show abc123

# Human-readable with memory info
hive tasks show abc123 --pretty
```

---

## üîß Configuration

### **Environment Variables**

Add to `.env.shared`:

```bash
# Vector Store
VECTOR_STORE_PROVIDER=chromadb
VECTOR_STORE_COLLECTION=hive_knowledge
VECTOR_DIMENSION=384

# Embedding Model
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Exa API (for future external search)
EXA_API_KEY=your-exa-key
```

### **Agent Configuration**

```python
# Enable RAG for agent
agent_config = AgentConfig(
    name="smart-agent",
    model="claude-3-sonnet",
    memory_enabled=True,  # Required for context injection
    max_tokens=4096
)
```

---

## üéØ Agent Tools

Your agents automatically get these tools when `context_service` is set:

### **1. search_long_term_memory**

```python
# Agent can call mid-task:
results = await agent.call_tool_async(
    'search_long_term_memory',
    query='database migration patterns',
    top_k=3
)
```

**Use cases**:
- "How did we handle similar deployments before?"
- "What errors occurred in previous migrations?"
- "What decisions were made about authentication?"

### **2. think** (existing)
```python
thoughts = await agent.call_tool_async(
    'think',
    prompt='What are the risks of this deployment?'
)
```

### **3. remember / recall** (existing)
```python
# Store in short-term memory
await agent.call_tool_async('remember', key='api_endpoint', value='https://api.prod')

# Retrieve later
endpoint = await agent.call_tool_async('recall', key='api_endpoint')
```

---

## üìä Monitoring

### **Check Librarian Stats**

```python
stats = await librarian.get_stats_async()
print(stats)
# {
#   "service": "librarian",
#   "status": "running",
#   "tasks_indexed": 42,
#   "vector_store": {...},
#   "embedding_manager": {...}
# }
```

### **Check Context Service Stats**

```python
stats = await context_service.get_stats_async()
print(stats)
# {
#   "service": "context_retrieval",
#   "vector_store_healthy": True,
#   "embedding_stats": {...}
# }
```

---

## üêõ Troubleshooting

### **Problem: "ChromaDB not installed"**

```bash
poetry add chromadb
# or
pip install chromadb
```

### **Problem: "Rich library not installed" (CLI)**

```bash
poetry add rich
# or
pip install rich
```

### **Problem: Context not injecting**

**Check**:
1. Is `context_service` set on agent? `agent.context_service = service`
2. Is `input_data` a dict with `task_id`? `{'task_id': '...'}`
3. Is agent's memory enabled? `config.memory_enabled = True`

**Debug**:
```python
# Enable debug logging
import logging
logging.getLogger('hive_ai.memory.context_service').setLevel(logging.DEBUG)
```

### **Problem: Librarian not indexing**

**Check**:
1. Is event bus running? `bus.status`
2. Are tasks completing? Check task status in DB
3. Is librarian started? `await librarian.start()`

**Debug**:
```python
# Manually index a task
await librarian.index_task_async('task-123')
```

---

## üí° Best Practices

### **1. Always provide task_id for context injection**

```python
# ‚úÖ Good - gets context
await agent.run_async({'task_id': 'task-123', 'data': {...}})

# ‚ùå Bad - no context
await agent.run_async({'data': {...}})
```

### **2. Use appropriate query modes**

```python
# Fast mode (default) - for most tasks
context = await service.get_context_for_task(task_id, mode='fast')

# Deep mode (future) - for complex analysis
context = await service.get_context_for_task(task_id, mode='deep')
```

### **3. Structure task payloads for better indexing**

```python
# Good structure
payload = {
    'errors': ['Error 1', 'Error 2'],  # Will be indexed as error fragments
    'decisions': ['Use PostgreSQL for persistence'],  # Decision fragments
    'artifacts': ['deploy.sh', 'config.yaml']  # Artifact fragments
}

task_id = create_task(
    title="Deploy v2.1",
    task_type="deployment",
    payload=payload
)
```

### **4. Monitor token usage**

```python
# Before Memory Nexus
initial_tokens = 8000

# After Memory Nexus (with context injection)
optimized_tokens = 1200  # 85% reduction!
```

---

## üéì Learning Path

1. **Day 1**: Setup & basic usage (this guide)
2. **Day 2**: Build custom agents with context
3. **Day 3**: Optimize fragment parsing for your domain
4. **Week 2**: Implement Curator mode (nightly maintenance)
5. **Week 3**: Add deep query mode (agent-refined searches)

---

## üìö Further Reading

- **Implementation Docs**: `claudedocs/intelligent_task_memory_nexus_implementation.md`
- **Architecture Decisions**: See implementation doc for Decision 1-C, 2-B, 3-C, 4-C, 6-C
- **Hive Archivist README**: `apps/hive-archivist/README.md`
- **Package READMEs**: `packages/hive-ai/README.md`, `packages/hive-orchestration/README.md`

---

**You're ready to build agents with infinite memory!** üöÄ

Questions? Check the implementation doc or debug logs.
