name: Hive Platform Integration Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run integration tests nightly at 2 AM UTC
    - cron: '0 2 * * *'

jobs:
  platform-validation:
    name: Platform Validation Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"

    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: latest
        virtualenvs-create: true
        virtualenvs-in-project: true

    - name: Load cached venv
      id: cached-poetry-dependencies
      uses: actions/cache@v3
      with:
        path: .venv
        key: venv-${{ runner.os }}-${{ steps.setup-python.outputs.python-version }}-${{ hashFiles('**/poetry.lock') }}

    - name: Install dependencies
      if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
      run: poetry install --no-interaction --no-root

    - name: Install project
      run: poetry install --no-interaction

    - name: Run Platform Validation Tests
      run: |
        poetry run python -m pytest tests/test_hive_platform_validation.py -v \
          --tb=short \
          --durations=10 \
          --timeout=300

    - name: Upload validation results
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: validation-test-results
        path: |
          test-results/
          *.log

  comprehensive-integration:
    name: Comprehensive Integration Tests
    runs-on: ubuntu-latest
    timeout-minutes: 45
    needs: platform-validation

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"

    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: latest
        virtualenvs-create: true
        virtualenvs-in-project: true

    - name: Load cached venv
      id: cached-poetry-dependencies
      uses: actions/cache@v3
      with:
        path: .venv
        key: venv-${{ runner.os }}-${{ steps.setup-python.outputs.python-version }}-${{ hashFiles('**/poetry.lock') }}

    - name: Install dependencies
      if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
      run: poetry install --no-interaction --no-root

    - name: Install project
      run: poetry install --no-interaction

    - name: Run Comprehensive Integration Tests
      run: |
        poetry run python tests/test_comprehensive_integration.py
      env:
        HIVE_TEST_MODE: "true"
        PYTHONPATH: ${{ github.workspace }}

    - name: Upload comprehensive test results
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: comprehensive-test-results
        path: |
          test-results/
          *.log
          /tmp/hive_integration_test_*/

  performance-benchmarks:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: platform-validation

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"

    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: latest
        virtualenvs-create: true
        virtualenvs-in-project: true

    - name: Load cached venv
      id: cached-poetry-dependencies
      uses: actions/cache@v3
      with:
        path: .venv
        key: venv-${{ runner.os }}-${{ steps.setup-python.outputs.python-version }}-${{ hashFiles('**/poetry.lock') }}

    - name: Install dependencies
      if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
      run: poetry install --no-interaction --no-root

    - name: Install project
      run: poetry install --no-interaction

    - name: Run Performance Benchmarks
      run: |
        poetry run python -c "
        from tests.test_comprehensive_integration import PerformanceIntegrationTests, PlatformTestEnvironment

        env = PlatformTestEnvironment()
        env.setup()

        try:
            perf_tests = PerformanceIntegrationTests(env)

            print('Running performance benchmarks...')
            async_result = perf_tests.test_async_infrastructure_performance()
            concurrent_result = perf_tests.test_concurrent_task_processing()
            db_result = perf_tests.test_database_connection_pooling()
            improvement_result = perf_tests.test_performance_improvement_claims()

            print(f'Async Infrastructure: {\"PASS\" if async_result else \"FAIL\"}')
            print(f'Concurrent Processing: {\"PASS\" if concurrent_result else \"FAIL\"}')
            print(f'Database Pooling: {\"PASS\" if db_result else \"FAIL\"}')
            print(f'Performance Improvements: {\"PASS\" if improvement_result else \"FAIL\"}')

            # Print performance metrics
            for sample in env.metrics.performance_samples:
                test_name = sample.get('test', 'unknown')
                if 'throughput' in sample:
                    print(f'{test_name}: {sample[\"throughput\"]:.2f} ops/sec')
                elif 'improvement_factor' in sample:
                    print(f'{test_name}: {sample[\"improvement_factor\"]:.1f}x improvement')

            # Exit with error if any test failed
            all_passed = all([async_result, concurrent_result, db_result, improvement_result])
            exit(0 if all_passed else 1)

        finally:
            env.teardown()
        "

    - name: Upload performance results
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: performance-benchmark-results
        path: |
          performance-results/
          *.json

  cross-platform-compatibility:
    name: Cross-Platform Compatibility
    runs-on: ${{ matrix.os }}
    timeout-minutes: 20
    needs: platform-validation

    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ["3.10", "3.11", "3.12"]
        exclude:
          # Reduce matrix size for efficiency
          - os: macos-latest
            python-version: "3.10"
          - os: windows-latest
            python-version: "3.10"

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: latest
        virtualenvs-create: true
        virtualenvs-in-project: true

    - name: Install dependencies
      run: poetry install --no-interaction --no-root

    - name: Install project
      run: poetry install --no-interaction

    - name: Run Platform Validation (Cross-Platform)
      run: |
        poetry run python -m pytest tests/test_hive_platform_validation.py::test_platform_health_check -v

    - name: Test Core Import Patterns
      run: |
        poetry run python -c "
        import sys
        from pathlib import Path

        # Test basic imports work across platforms
        test_root = Path('.')
        sys.path.insert(0, str(test_root / 'apps' / 'hive-orchestrator' / 'src'))

        try:
            import hive_orchestrator
            print('‚úÖ Hive orchestrator imports work')
        except ImportError as e:
            print(f'‚ùå Import failed: {e}')
            sys.exit(1)

        print('‚úÖ Cross-platform compatibility validated')
        "

  security-integration:
    name: Security Integration Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: platform-validation

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"

    - name: Install Poetry
      uses: snok/install-poetry@v1

    - name: Install dependencies
      run: poetry install --no-interaction

    - name: Run Security Checks
      run: |
        # Install security tools
        poetry run pip install bandit safety

        # Run bandit security linter
        poetry run bandit -r apps/ -f json -o security-report.json || true

        # Check for known vulnerabilities
        poetry run safety check --json --output safety-report.json || true

        # Run basic security integration tests
        poetry run python -c "
        import sqlite3
        import tempfile
        import json
        from pathlib import Path

        print('üîí Running security integration tests...')

        # Test 1: SQL injection protection
        temp_db = tempfile.mktemp(suffix='.db')
        conn = sqlite3.connect(temp_db)
        conn.execute('CREATE TABLE test (id TEXT, data TEXT)')

        # This should not cause SQL injection
        malicious_input = \"'; DROP TABLE test; --\"
        try:
            conn.execute('INSERT INTO test (id, data) VALUES (?, ?)', ('test', malicious_input))
            conn.execute('SELECT COUNT(*) FROM test')
            print('‚úÖ SQL injection protection working')
        except:
            print('‚ùå SQL injection vulnerability detected')
            exit(1)

        # Test 2: JSON payload validation
        try:
            malicious_json = '{\"__proto__\": {\"isAdmin\": true}}'
            parsed = json.loads(malicious_json)
            # Should not have prototype pollution
            if hasattr(parsed, 'isAdmin'):
                print('‚ùå JSON prototype pollution vulnerability')
                exit(1)
            print('‚úÖ JSON parsing secure')
        except:
            print('‚ùå JSON parsing error')
            exit(1)

        print('‚úÖ Security integration tests passed')
        "

    - name: Upload security results
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: security-test-results
        path: |
          security-report.json
          safety-report.json

  integration-summary:
    name: Integration Test Summary
    runs-on: ubuntu-latest
    needs: [platform-validation, comprehensive-integration, performance-benchmarks, cross-platform-compatibility, security-integration]
    if: always()

    steps:
    - name: Download all artifacts
      uses: actions/download-artifact@v3

    - name: Generate Integration Report
      run: |
        echo "# Hive Platform Integration Test Report" > integration-report.md
        echo "" >> integration-report.md
        echo "**Test Run:** $(date)" >> integration-report.md
        echo "**Commit:** ${{ github.sha }}" >> integration-report.md
        echo "**Branch:** ${{ github.ref_name }}" >> integration-report.md
        echo "" >> integration-report.md

        echo "## Test Results Summary" >> integration-report.md
        echo "" >> integration-report.md

        # Check job results
        echo "| Test Suite | Status |" >> integration-report.md
        echo "|------------|--------|" >> integration-report.md
        echo "| Platform Validation | ${{ needs.platform-validation.result == 'success' && '‚úÖ PASSED' || '‚ùå FAILED' }} |" >> integration-report.md
        echo "| Comprehensive Integration | ${{ needs.comprehensive-integration.result == 'success' && '‚úÖ PASSED' || '‚ùå FAILED' }} |" >> integration-report.md
        echo "| Performance Benchmarks | ${{ needs.performance-benchmarks.result == 'success' && '‚úÖ PASSED' || '‚ùå FAILED' }} |" >> integration-report.md
        echo "| Cross-Platform Compatibility | ${{ needs.cross-platform-compatibility.result == 'success' && '‚úÖ PASSED' || '‚ùå FAILED' }} |" >> integration-report.md
        echo "| Security Integration | ${{ needs.security-integration.result == 'success' && '‚úÖ PASSED' || '‚ùå FAILED' }} |" >> integration-report.md
        echo "" >> integration-report.md

        # Overall status
        if [[ "${{ needs.platform-validation.result }}" == "success" &&
              "${{ needs.comprehensive-integration.result }}" == "success" &&
              "${{ needs.performance-benchmarks.result }}" == "success" &&
              "${{ needs.cross-platform-compatibility.result }}" == "success" &&
              "${{ needs.security-integration.result }}" == "success" ]]; then
          echo "## üéâ Overall Status: ALL TESTS PASSED" >> integration-report.md
          echo "" >> integration-report.md
          echo "The Hive platform is functioning correctly across all integration test categories." >> integration-report.md
          echo "‚úÖ Ready for production deployment" >> integration-report.md
        else
          echo "## ‚ùå Overall Status: SOME TESTS FAILED" >> integration-report.md
          echo "" >> integration-report.md
          echo "The Hive platform has integration issues that need to be addressed." >> integration-report.md
          echo "üîß Review failed tests before production deployment" >> integration-report.md
        fi

        echo "" >> integration-report.md
        echo "## Artifacts" >> integration-report.md
        echo "- Test results and logs available in job artifacts" >> integration-report.md
        echo "- Performance metrics and benchmarks included" >> integration-report.md
        echo "- Security scan results attached" >> integration-report.md

        cat integration-report.md

    - name: Upload Integration Report
      uses: actions/upload-artifact@v3
      with:
        name: integration-test-report
        path: integration-report.md

    - name: Comment PR (if applicable)
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const report = fs.readFileSync('integration-report.md', 'utf8');

          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: report
          });

    - name: Set final status
      run: |
        if [[ "${{ needs.platform-validation.result }}" == "success" &&
              "${{ needs.comprehensive-integration.result }}" == "success" &&
              "${{ needs.performance-benchmarks.result }}" == "success" &&
              "${{ needs.cross-platform-compatibility.result }}" == "success" &&
              "${{ needs.security-integration.result }}" == "success" ]]; then
          echo "‚úÖ All integration tests passed successfully"
          exit 0
        else
          echo "‚ùå Some integration tests failed"
          exit 1
        fi