name: 📊 Log Intelligence Analysis

on:
  schedule:
    # Run daily at 6 AM UTC for daily digest
    - cron: '0 6 * * *'
  workflow_dispatch:
    # Allow manual triggering
    inputs:
      hours_back:
        description: 'Hours of log history to analyze'
        required: false
        default: '24'
        type: string
      log_directories:
        description: 'Comma-separated log directories to analyze'
        required: false
        default: 'logs,apps/*/logs'
        type: string

permissions:
  contents: read
  issues: write

jobs:
  log-intelligence:
    runs-on: ubuntu-latest
    name: Log Intelligence Analysis
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        pip install python-dateutil
        
    - name: Prepare log directories
      run: |
        # Create log directories if they don't exist
        mkdir -p logs
        
        # Copy any existing logs from various locations
        find . -name "*.log" -type f -not -path "./.git/*" -not -path "./node_modules/*" | head -20 | while read logfile; do
          cp "$logfile" logs/ 2>/dev/null || true
        done
        
        # Create sample logs for demonstration if no logs exist
        if [ ! "$(ls -A logs)" ]; then
          echo "$(date -u +"%Y-%m-%dT%H:%M:%S.%3NZ") [INFO] Log Intelligence System initialized" > logs/system.log
          echo "$(date -u +"%Y-%m-%dT%H:%M:%S.%3NZ") [ERROR] Sample error for testing log analysis" >> logs/system.log
          echo "$(date -u +"%Y-%m-%dT%H:%M:%S.%3NZ") [WARNING] Sample warning message" >> logs/system.log
        fi
        
    - name: Run log intelligence analysis
      id: analysis
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        # Parse log directories from input
        LOG_DIRS="${{ github.event.inputs.log_directories || 'logs' }}"
        HOURS="${{ github.event.inputs.hours_back || '24' }}"
        
        # Convert comma-separated directories to space-separated
        LOG_DIRS_ARGS=$(echo "$LOG_DIRS" | tr ',' ' ')
        
        python scripts/monitoring/log_intelligence.py \
          --log-dirs $LOG_DIRS_ARGS \
          --hours $HOURS \
          --output-format markdown
        
    - name: Create or update log digest issue
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          
          // Read log analysis results
          let digestContent = '';
          try {
            digestContent = fs.readFileSync('daily_log_digest.md', 'utf8');
          } catch (error) {
            console.log('No log digest file found');
            return;
          }
          
          // Look for existing log digest issue
          const issues = await github.rest.issues.listForRepo({
            owner: context.repo.owner,
            repo: context.repo.repo,
            labels: ['log-digest', 'automated'],
            state: 'open'
          });
          
          const issueTitle = '📊 Daily Log Intelligence Digest';
          const issueBody = `# Daily Log Analysis Report
          
          This issue contains the automated daily analysis of system logs.
          
          ${digestContent}
          
          ---
          
          **Instructions:**
          - Review critical issues and error trends
          - Investigate any security alerts immediately
          - Address performance issues during maintenance windows
          - Close this issue when all items are reviewed
          
          *Generated by Log Intelligence System on ${new Date().toISOString()}*`;
          
          if (issues.data.length > 0) {
            // Update existing issue
            const issue = issues.data[0];
            await github.rest.issues.update({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issue.number,
              title: issueTitle,
              body: issueBody
            });
            
            // Add comment about new analysis
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issue.number,
              body: `## 📈 Daily Log Update - ${new Date().toLocaleDateString()}
              
              New log analysis completed. Please review the updated digest above for any critical issues or trends.`
            });
          } else {
            // Create new issue
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: issueTitle,
              body: issueBody,
              labels: ['log-digest', 'automated', 'monitoring']
            });
          }
          
    - name: Create critical alert issue
      if: steps.analysis.outputs.has_critical_issues == 'true'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          
          // Read analysis results
          let analysisResults = {};
          try {
            const resultsContent = fs.readFileSync('log_intelligence_results.json', 'utf8');
            analysisResults = JSON.parse(resultsContent);
          } catch (error) {
            console.log('No analysis results file found');
            return;
          }
          
          if (!analysisResults.critical_patterns || analysisResults.critical_patterns.length === 0) {
            return;
          }
          
          // Create critical alert issue
          const criticalCount = analysisResults.critical_patterns.length;
          const timestamp = new Date().toISOString();
          
          let issueBody = `# 🚨 Critical Log Alerts Detected
          
          **Alert Time**: ${timestamp}
          **Critical Issues**: ${criticalCount}
          **Analysis Period**: Last ${analysisResults.time_window_hours || 24} hours
          
          ## 🔍 Critical Issues
          
          `;
          
          analysisResults.critical_patterns.forEach((issue, index) => {
            issueBody += `### ${index + 1}. ${issue.pattern}
          
          - **Source**: ${issue.source}
          - **Time**: ${issue.timestamp}
          - **Message**: \`${issue.message}\`
          - **Severity**: ${issue.severity}
          
          `;
          });
          
          issueBody += `
          ## 🎯 Immediate Actions Required
          
          1. **Investigate** each critical issue immediately
          2. **Check system status** and resource utilization
          3. **Review recent deployments** or configuration changes
          4. **Escalate** if issues persist or worsen
          5. **Update** this issue with investigation findings
          
          ## 📊 Analysis Summary
          
          - **Total Log Entries**: ${analysisResults.total_entries?.toLocaleString() || 'N/A'}
          - **Error Count**: ${analysisResults.error_count?.toLocaleString() || 'N/A'}
          - **Warning Count**: ${analysisResults.warning_count?.toLocaleString() || 'N/A'}
          - **Performance Issues**: ${analysisResults.performance_issues?.length || 0}
          - **Security Alerts**: ${analysisResults.security_alerts?.length || 0}
          
          ---
          
          **Auto-generated by Log Intelligence System**
          **Next Analysis**: Tomorrow at 6 AM UTC
          
          @${context.repo.owner} - Critical log issues require immediate attention!`;
          
          // Create critical alert issue
          await github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: `🚨 Critical Log Alerts - ${criticalCount} Issue(s) Detected`,
            body: issueBody,
            labels: ['critical', 'logs', 'automated', 'urgent'],
            assignees: [context.repo.owner]
          });
          
    - name: Upload analysis artifacts
      uses: actions/upload-artifact@v4
      with:
        name: log-intelligence-analysis
        path: |
          log_intelligence_results.json
          daily_log_digest.md
        retention-days: 30
