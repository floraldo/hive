#!/usr/bin/env python3
"""
End-to-End Integration Test for AI Planner â†’ Queen â†’ Worker Pipeline

Tests the complete autonomous task execution flow in a simulated environment
to validate that all components work together correctly.
"""

import asyncio
import json
import pytest
import sqlite3
import tempfile
import time
import uuid
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, Any, List
from unittest.mock import Mock, patch, MagicMock

# Test imports
import sys
import os

# Add paths for test imports
test_root = Path(__file__).parent.parent
sys.path.insert(0, str(test_root / "apps" / "hive-orchestrator" / "src"))
sys.path.insert(0, str(test_root / "apps" / "ai-planner" / "src"))


class EndToEndIntegrationTest:
    """Complete end-to-end test of the AI Planner â†’ Queen â†’ Worker pipeline"""

    def setup_method(self):
        """Setup test environment"""
        # Create temporary database
        self.temp_db_fd, self.temp_db_path = tempfile.mkstemp(suffix=".db")
        os.close(self.temp_db_fd)

        # Initialize test database
        self.init_test_database()

        # Mock configuration
        self.mock_config = {
            "max_parallel_per_role": {"backend": 2, "frontend": 1, "infra": 1},
            "orchestration": {"status_refresh_seconds": 1, "task_retry_limit": 2, "graceful_shutdown_seconds": 5},
            "worker_timeout_minutes": 30,
            "zombie_detection_minutes": 5,
        }

        # Statistics tracking
        self.test_stats = {
            "tasks_created": 0,
            "plans_generated": 0,
            "subtasks_created": 0,
            "tasks_completed": 0,
            "errors": [],
        }

    def teardown_method(self):
        """Cleanup test environment"""
        try:
            os.unlink(self.temp_db_path)
        except:
            pass

    def init_test_database(self):
        """Initialize test database with required schema"""
        conn = sqlite3.connect(self.temp_db_path)
        conn.executescript(
            """
            -- Planning queue for AI Planner input
            CREATE TABLE planning_queue (
                id TEXT PRIMARY KEY,
                task_description TEXT NOT NULL,
                priority INTEGER DEFAULT 50,
                requestor TEXT,
                context_data TEXT,
                complexity_estimate TEXT,
                status TEXT DEFAULT 'pending',
                assigned_agent TEXT,
                assigned_at TEXT,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                completed_at TEXT
            );

            -- Execution plans generated by AI Planner
            CREATE TABLE execution_plans (
                id TEXT PRIMARY KEY,
                planning_task_id TEXT NOT NULL,
                plan_data TEXT NOT NULL,
                estimated_complexity TEXT,
                estimated_duration INTEGER,
                status TEXT DEFAULT 'generated',
                generated_at TEXT DEFAULT CURRENT_TIMESTAMP,
                updated_at TEXT DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (planning_task_id) REFERENCES planning_queue (id)
            );

            -- Tasks executed by Queen and Workers
            CREATE TABLE tasks (
                id TEXT PRIMARY KEY,
                title TEXT NOT NULL,
                description TEXT,
                task_type TEXT DEFAULT 'task',
                priority INTEGER DEFAULT 50,
                status TEXT DEFAULT 'queued',
                assignee TEXT,
                assigned_at TEXT,
                started_at TEXT,
                completed_at TEXT,
                payload TEXT,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                updated_at TEXT DEFAULT CURRENT_TIMESTAMP,
                retry_count INTEGER DEFAULT 0,
                workspace TEXT,
                tags TEXT
            );

            -- Worker execution runs
            CREATE TABLE runs (
                id TEXT PRIMARY KEY,
                task_id TEXT NOT NULL,
                worker_id TEXT NOT NULL,
                phase TEXT,
                status TEXT DEFAULT 'running',
                result TEXT,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                completed_at TEXT,
                FOREIGN KEY (task_id) REFERENCES tasks (id)
            );

            -- Worker registry
            CREATE TABLE workers (
                id TEXT PRIMARY KEY,
                role TEXT NOT NULL,
                capabilities TEXT,
                metadata TEXT,
                status TEXT DEFAULT 'active',
                created_at TEXT DEFAULT CURRENT_TIMESTAMP
            );

            -- Event tracking
            CREATE TABLE events (
                id TEXT PRIMARY KEY,
                event_type TEXT NOT NULL,
                source_agent TEXT,
                target_agent TEXT,
                payload TEXT,
                correlation_id TEXT,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP
            );

            -- Performance indexes
            CREATE INDEX idx_planning_queue_status_priority ON planning_queue (status, priority DESC, created_at);
            CREATE INDEX idx_execution_plans_status ON execution_plans (status);
            CREATE INDEX idx_tasks_status_type ON tasks (status, task_type);
            CREATE INDEX idx_tasks_payload_parent ON tasks (json_extract(payload, '$.parent_plan_id'));
            CREATE INDEX idx_runs_task_status ON runs (task_id, status);
        """
        )
        conn.commit()
        conn.close()

    def get_test_connection(self):
        """Get connection to test database"""
        return sqlite3.connect(self.temp_db_path)

    def create_planning_task(self, description: str, priority: int = 50, context: Dict = None) -> str:
        """Create a task in the planning queue"""
        task_id = str(uuid.uuid4())
        conn = self.get_test_connection()

        conn.execute(
            """
            INSERT INTO planning_queue (id, task_description, priority, requestor, context_data)
            VALUES (?, ?, ?, ?, ?)
        """,
            (task_id, description, priority, "test_system", json.dumps(context or {})),
        )

        conn.commit()
        conn.close()

        self.test_stats["tasks_created"] += 1
        return task_id

    def simulate_ai_planner_processing(self, task_id: str) -> str:
        """Simulate AI Planner processing a task and generating an execution plan"""
        conn = self.get_test_connection()

        # Mark task as assigned
        conn.execute(
            """
            UPDATE planning_queue
            SET status = 'assigned', assigned_agent = 'ai-planner-test'
            WHERE id = ?
        """,
            (task_id,),
        )

        # Generate mock execution plan
        plan_id = f"plan_{uuid.uuid4()}"
        plan_data = {
            "plan_id": plan_id,
            "task_id": task_id,
            "plan_name": "Test Authentication Implementation",
            "sub_tasks": [
                {
                    "id": "auth_design",
                    "title": "Design Authentication Schema",
                    "description": "Create database schema and API design for authentication",
                    "assignee": "worker:backend",
                    "complexity": "medium",
                    "estimated_duration": 30,
                    "workflow_phase": "design",
                    "required_skills": ["database_design", "api_design"],
                    "deliverables": ["auth_schema.sql", "auth_api.yaml"],
                    "dependencies": [],
                },
                {
                    "id": "auth_impl",
                    "title": "Implement Authentication Service",
                    "description": "Implement JWT-based authentication service",
                    "assignee": "worker:backend",
                    "complexity": "medium",
                    "estimated_duration": 45,
                    "workflow_phase": "implementation",
                    "required_skills": ["python", "jwt", "flask"],
                    "deliverables": ["auth_service.py", "test_auth.py"],
                    "dependencies": ["auth_design"],
                },
                {
                    "id": "auth_frontend",
                    "title": "Create Login UI",
                    "description": "Create login form and authentication UI components",
                    "assignee": "worker:frontend",
                    "complexity": "simple",
                    "estimated_duration": 25,
                    "workflow_phase": "implementation",
                    "required_skills": ["react", "javascript", "css"],
                    "deliverables": ["LoginForm.jsx", "AuthProvider.jsx"],
                    "dependencies": ["auth_design"],
                },
            ],
            "metrics": {"total_estimated_duration": 100, "complexity_breakdown": {"simple": 1, "medium": 2}},
            "status": "generated",
            "created_at": datetime.now(timezone.utc).isoformat(),
        }

        # Insert execution plan
        conn.execute(
            """
            INSERT INTO execution_plans (id, planning_task_id, plan_data, estimated_complexity, estimated_duration, status)
            VALUES (?, ?, ?, ?, ?, ?)
        """,
            (plan_id, task_id, json.dumps(plan_data), "medium", 100, "generated"),
        )

        # Create subtasks
        for sub_task in plan_data["sub_tasks"]:
            subtask_id = f"subtask_{plan_id}_{sub_task['id']}"

            payload = {
                "parent_plan_id": plan_id,
                "subtask_id": sub_task["id"],
                "complexity": sub_task["complexity"],
                "estimated_duration": sub_task["estimated_duration"],
                "workflow_phase": sub_task["workflow_phase"],
                "required_skills": sub_task["required_skills"],
                "deliverables": sub_task["deliverables"],
                "dependencies": sub_task["dependencies"],
                "assignee": sub_task["assignee"],
            }

            conn.execute(
                """
                INSERT INTO tasks (
                    id, title, description, task_type, priority, status,
                    assignee, payload, created_at, updated_at
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
            """,
                (
                    subtask_id,
                    sub_task["title"],
                    sub_task["description"],
                    "planned_subtask",
                    50,
                    "queued",
                    sub_task["assignee"],
                    json.dumps(payload),
                ),
            )

            self.test_stats["subtasks_created"] += 1

        # Mark planning task as completed
        conn.execute(
            """
            UPDATE planning_queue SET status = 'planned', completed_at = CURRENT_TIMESTAMP WHERE id = ?
        """,
            (task_id,),
        )

        conn.commit()
        conn.close()

        self.test_stats["plans_generated"] += 1
        return plan_id

    def get_ready_subtasks(self) -> List[Dict[str, Any]]:
        """Get subtasks that are ready for execution (dependencies met)"""
        conn = self.get_test_connection()

        # Query for ready subtasks with dependency checking
        cursor = conn.execute(
            """
            WITH ready_subtasks AS (
                SELECT
                    t.*,
                    ep.status as plan_status
                FROM tasks t
                INNER JOIN execution_plans ep
                    ON ep.id = json_extract(t.payload, '$.parent_plan_id')
                WHERE t.task_type = 'planned_subtask'
                    AND t.status = 'queued'
                    AND ep.status IN ('generated', 'approved', 'executing')
            )
            SELECT * FROM ready_subtasks
            ORDER BY priority DESC, created_at ASC
        """
        )

        rows = cursor.fetchall()
        subtasks = []

        for row in rows:
            # Build subtask dictionary
            subtask = {
                "id": row[0],
                "title": row[1],
                "description": row[2],
                "task_type": row[3],
                "priority": row[4],
                "status": row[5],
                "assignee": row[6],
                "payload": json.loads(row[10]) if row[10] else {},
                "created_at": row[11],
            }

            # Check dependencies
            payload = subtask["payload"]
            dependencies = payload.get("dependencies", [])
            dependencies_met = True

            if dependencies:
                for dep_id in dependencies:
                    # Check if dependency is completed
                    dep_cursor = conn.execute(
                        """
                        SELECT status FROM tasks
                        WHERE json_extract(payload, '$.subtask_id') = ?
                        AND json_extract(payload, '$.parent_plan_id') = ?
                    """,
                        (dep_id, payload.get("parent_plan_id")),
                    )

                    dep_row = dep_cursor.fetchone()
                    if not dep_row or dep_row[0] != "completed":
                        dependencies_met = False
                        break

            if dependencies_met:
                subtasks.append(subtask)

        conn.close()
        return subtasks

    def simulate_queen_processing(self):
        """Simulate Queen picking up and processing ready subtasks"""
        ready_subtasks = self.get_ready_subtasks()

        if not ready_subtasks:
            return []

        conn = self.get_test_connection()
        processed_tasks = []

        for subtask in ready_subtasks:
            task_id = subtask["id"]

            # Simulate Queen assigning task to worker
            conn.execute(
                """
                UPDATE tasks
                SET status = 'assigned', assigned_at = CURRENT_TIMESTAMP
                WHERE id = ?
            """,
                (task_id,),
            )

            # Simulate task starting
            conn.execute(
                """
                UPDATE tasks
                SET status = 'in_progress', started_at = CURRENT_TIMESTAMP
                WHERE id = ?
            """,
                (task_id,),
            )

            # Create run record
            run_id = f"run_{uuid.uuid4()}"
            conn.execute(
                """
                INSERT INTO runs (id, task_id, worker_id, phase, status)
                VALUES (?, ?, ?, ?, ?)
            """,
                (run_id, task_id, "test_worker", "apply", "running"),
            )

            processed_tasks.append({"task_id": task_id, "run_id": run_id, "title": subtask["title"]})

        conn.commit()
        conn.close()

        return processed_tasks

    def simulate_worker_completion(self, task_id: str, run_id: str, success: bool = True):
        """Simulate worker completing a task"""
        conn = self.get_test_connection()

        # Update run result
        result = {
            "status": "success" if success else "failed",
            "output": "Task completed successfully" if success else "Task failed with error",
            "timestamp": datetime.now(timezone.utc).isoformat(),
        }

        conn.execute(
            """
            UPDATE runs
            SET status = ?, result = ?, completed_at = CURRENT_TIMESTAMP
            WHERE id = ?
        """,
            ("completed" if success else "failed", json.dumps(result), run_id),
        )

        # Update task status
        task_status = "completed" if success else "failed"
        conn.execute(
            """
            UPDATE tasks
            SET status = ?, completed_at = CURRENT_TIMESTAMP
            WHERE id = ?
        """,
            (task_status, task_id),
        )

        conn.commit()
        conn.close()

        if success:
            self.test_stats["tasks_completed"] += 1

    def check_plan_completion(self, plan_id: str) -> Dict[str, Any]:
        """Check if an execution plan is complete"""
        conn = self.get_test_connection()

        # Get all subtasks for this plan
        cursor = conn.execute(
            """
            SELECT status FROM tasks
            WHERE task_type = 'planned_subtask'
            AND json_extract(payload, '$.parent_plan_id') = ?
        """,
            (plan_id,),
        )

        statuses = [row[0] for row in cursor.fetchall()]
        total_tasks = len(statuses)

        if total_tasks == 0:
            conn.close()
            return {"complete": False, "progress": 0, "total_tasks": 0}

        completed_tasks = sum(1 for s in statuses if s == "completed")
        failed_tasks = sum(1 for s in statuses if s == "failed")
        in_progress_tasks = sum(1 for s in statuses if s in ["assigned", "in_progress"])

        progress = (completed_tasks / total_tasks) * 100
        is_complete = completed_tasks == total_tasks

        conn.close()

        return {
            "complete": is_complete,
            "progress": progress,
            "total_tasks": total_tasks,
            "completed_tasks": completed_tasks,
            "failed_tasks": failed_tasks,
            "in_progress_tasks": in_progress_tasks,
        }

    def test_complete_pipeline(self):
        """Test the complete AI Planner â†’ Queen â†’ Worker pipeline"""
        print("\nðŸš€ Starting End-to-End Integration Test")

        # Step 1: Create planning task
        print("\nðŸ“‹ Step 1: Creating planning task...")
        task_description = "Implement complete authentication system with JWT tokens"
        planning_task_id = self.create_planning_task(
            task_description, priority=75, context={"complexity": "high", "estimated_hours": 8}
        )
        print(f"âœ… Created planning task: {planning_task_id}")

        # Step 2: Simulate AI Planner processing
        print("\nðŸ¤– Step 2: AI Planner processing...")
        plan_id = self.simulate_ai_planner_processing(planning_task_id)
        print(f"âœ… Generated execution plan: {plan_id}")
        print(f"   Created {self.test_stats['subtasks_created']} subtasks")

        # Step 3: Simulate Queen processing cycles
        print("\nðŸ‘‘ Step 3: Queen processing cycles...")
        cycle = 0
        max_cycles = 10

        while cycle < max_cycles:
            cycle += 1
            print(f"\n   Cycle {cycle}:")

            # Get ready subtasks
            ready_subtasks = self.get_ready_subtasks()
            print(f"   ðŸ“ Found {len(ready_subtasks)} ready subtasks")

            if not ready_subtasks:
                print("   â¸ï¸ No ready subtasks, checking plan completion...")
                completion = self.check_plan_completion(plan_id)
                if completion["complete"]:
                    print(
                        f"   ðŸŽ‰ Plan completed! {completion['completed_tasks']}/{completion['total_tasks']} tasks done"
                    )
                    break
                else:
                    print(f"   â³ Plan in progress: {completion['progress']:.1f}% complete")
                    time.sleep(0.1)  # Brief pause in test
                    continue

            # Process ready subtasks
            processed = self.simulate_queen_processing()
            print(f"   ðŸ”„ Queen processed {len(processed)} subtasks")

            # Simulate worker completion
            for task_info in processed:
                print(f"   âš™ï¸ Worker executing: {task_info['title']}")
                # Simulate execution time with immediate completion for testing
                self.simulate_worker_completion(task_info["task_id"], task_info["run_id"], success=True)
                print(f"   âœ… Completed: {task_info['title']}")

            # Check progress
            completion = self.check_plan_completion(plan_id)
            print(
                f"   ðŸ“Š Plan progress: {completion['progress']:.1f}% ({completion['completed_tasks']}/{completion['total_tasks']})"
            )

        # Step 4: Verify final state
        print("\nðŸ” Step 4: Verifying final state...")
        final_completion = self.check_plan_completion(plan_id)

        # Assertions
        assert final_completion["complete"], f"Plan should be complete but is {final_completion['progress']:.1f}% done"
        assert (
            final_completion["failed_tasks"] == 0
        ), f"No tasks should fail but {final_completion['failed_tasks']} failed"
        assert (
            self.test_stats["tasks_completed"] == 3
        ), f"Should complete 3 tasks but completed {self.test_stats['tasks_completed']}"

        print(f"âœ… All assertions passed!")
        print(f"ðŸ“Š Final Statistics:")
        print(f"   Planning tasks created: {self.test_stats['tasks_created']}")
        print(f"   Execution plans generated: {self.test_stats['plans_generated']}")
        print(f"   Subtasks created: {self.test_stats['subtasks_created']}")
        print(f"   Tasks completed: {self.test_stats['tasks_completed']}")
        print(f"   Errors: {len(self.test_stats['errors'])}")

        print(f"\nðŸŽ‰ End-to-End Integration Test PASSED!")

    def test_dependency_resolution(self):
        """Test that dependencies are properly resolved"""
        print("\nðŸ”— Testing Dependency Resolution...")

        # Create planning task
        planning_task_id = self.create_planning_task("Test dependency resolution")
        plan_id = self.simulate_ai_planner_processing(planning_task_id)

        # Initial state: only task with no dependencies should be ready
        ready_subtasks = self.get_ready_subtasks()
        ready_titles = [task["title"] for task in ready_subtasks]

        print(f"Initially ready tasks: {ready_titles}")
        assert "Design Authentication Schema" in ready_titles, "Design task should be ready (no dependencies)"
        assert (
            "Implement Authentication Service" not in ready_titles
        ), "Implementation should not be ready (has dependencies)"
        assert "Create Login UI" not in ready_titles, "Frontend should not be ready (has dependencies)"

        # Complete the design task
        design_task = next(task for task in ready_subtasks if "Design" in task["title"])
        processed = self.simulate_queen_processing()
        self.simulate_worker_completion(design_task["id"], f"run_{uuid.uuid4()}", success=True)

        # Now both dependent tasks should be ready
        ready_subtasks = self.get_ready_subtasks()
        ready_titles = [task["title"] for task in ready_subtasks]

        print(f"After design completion: {ready_titles}")
        assert "Implement Authentication Service" in ready_titles, "Implementation should now be ready"
        assert "Create Login UI" in ready_titles, "Frontend should now be ready"

        print("âœ… Dependency resolution test passed!")

    def test_error_recovery(self):
        """Test error handling and recovery mechanisms"""
        print("\nðŸ› ï¸ Testing Error Recovery...")

        # Create planning task
        planning_task_id = self.create_planning_task("Test error recovery")
        plan_id = self.simulate_ai_planner_processing(planning_task_id)

        # Get first ready task
        ready_subtasks = self.get_ready_subtasks()
        first_task = ready_subtasks[0]

        # Process and fail the task
        processed = self.simulate_queen_processing()
        self.simulate_worker_completion(first_task["id"], f"run_{uuid.uuid4()}", success=False)

        # Check that the plan shows failure
        completion = self.check_plan_completion(plan_id)
        assert completion["failed_tasks"] == 1, f"Should have 1 failed task but got {completion['failed_tasks']}"

        print(f"âœ… Error recovery test passed! Failed tasks properly tracked.")

    def run_all_tests(self):
        """Run all integration tests"""
        try:
            self.test_complete_pipeline()
            self.test_dependency_resolution()
            self.test_error_recovery()
            print(f"\nðŸ† ALL INTEGRATION TESTS PASSED!")
            return True
        except Exception as e:
            print(f"\nâŒ INTEGRATION TEST FAILED: {e}")
            import traceback

            traceback.print_exc()
            return False


def test_end_to_end_integration():
    """Pytest entry point for end-to-end integration test"""
    test = EndToEndIntegrationTest()
    test.setup_method()
    try:
        success = test.run_all_tests()
        assert success, "End-to-end integration test failed"
    finally:
        test.teardown_method()


if __name__ == "__main__":
    # Run standalone tests
    test = EndToEndIntegrationTest()
    test.setup_method()
    try:
        test.run_all_tests()
    finally:
        test.teardown_method()
